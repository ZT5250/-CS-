202304计算机系统结构
#自考#自考复习#计算机系统结构

计算机系统层次结构
从使用语言的角度,按功能划分,层次结构由高到低依次为应用语言机器级、高级语言机器 级、汇编语言机器级、操作系统机器级、传统机器语言机器级和微程序机器级

￼
各机器级的实现采用翻译技术或解释技术，或者是这两种技术的结合.
翻译 (Translation )技术是先用转换程序将高一级机器级 上的程序整个地变换成低一级机器级上等效的程序,然后在低一级机器级上实现的技术.
解 释 (I n t e r p r e t a t i o n ) 技 术 则 是 在 低 级 机 器 级 上用 它 的 一 串 语 句 或 指 令 来 仿 真 高 级 机 器 级 上的 一 条 语 句 或 指 令的 功 能 ， 是 通 过 对 高 级 机器级语言程序中的每条语句或指令逐条解释来实现的技术。

M0用硬件实现，M1用微程序 (固件)实现，M2 到M5 大多是 用软件实现.所谓固件,是一种具有软件功能的硬件.

计算机系统结构、计算机组成和计算机实现
系统结构是对计算机系统中各级界面的定义及其上下的功能分配
透明:如果客观存在的事物或属性从某个角度看不到,则称对它是透明的,
计算机系统结构研究的是软、硬件之间的功能分配以及对传统机器级界面的确定.
计算机系统结构的属性包括:数据表示、寻址方式、寄存器组织、指令系统、存储系统组织、中断机构、系统机器级的管态和用户态的定义与切换、机器级I/O结构、系统各部分的信息保护方式和保护机构等属性.

计算机组成指的是计算机系统结构的逻辑实现,包括机器级内部的数据流和控制流的组成以及逻辑设计等.
计算机组成设计主要是围绕提高速度,着重提高操作的并行度、重叠度,以及功能的分散和设置专用功能部件来进行的.
要解决的问题: 在希望达到性能和价格的情况下, 如何更好、更合理地把各种设备和部件组织成计算机, 实现所确定的系统结构.
计算机组成设计要确定的方面一般包括:数据通路宽度、专用部件的设置、各种操作对部件的共享程度、功能部件的并行度、控制机构的组成方式、缓冲和排队技术、预估、预判技术和可靠性技术

计算机实现指的是计算机组成的物理实现,包括处理机、主存等部件的物理结构,器件的集成度和速度,器件、模块、插件、底板的划分与连接,专用器件的设计,微组装技术,信号传输,电源、冷却及整机装配技术等
计算机实现的设计着眼于器件技术和微组装技术,其中器件技术起着主导作用.

指令系统的确定属于计算机系统结构.指令的实现,如取指令、指令操作码译码、计算机操作数地址、取数、
运算、送结果等的操作安排和排序属于计算机组成. 实现这些指令功能的具体电路、器件的设计及装配技术属于计算机实现.
IBM370均由中央处理机/主存-通道-设备控制器-外设4级构成,以主存为中心,采用通道方式输入/输出.
设计何种系列机属于计算机系统结构,而系列内不同型号计算机的组成属于计算机组成.

计算机系统结构、组成、实现三者互不相同,但又相互影响.组成也会影响结构.系统结构的设计必须综合应用考虑, 为软件和算法的实现提供更多、更好的支持, 同时还要考虑可能采用和准备采用的组成技术.组成设计向上决定于结构,向下受限于实现技术.可以于实现折中权衡.结构、组成和实现所包含的内容随着不同的时期及不同的计算机系统也会有差异.

计算机系统结构设计的任务是进行软硬件的功能分配,确定传统机器级的软硬件界面.研究的是软硬件的功能分配以及如何更好、更合理地实现分配给硬件的功能.可把着眼于软硬件功能分配和确定程序设计者所看到的机器级界面的计算机系统结构,称为程序设计者看到的计算机系统结构;而把着眼于如何更好、更合理地实现分配给硬件的功能的计算机组成,称为计算机设计者看到的计算机系统结构

计算机系统的软硬件取舍及定量设计原理
软硬件的功能分配是计算机系统结构的主要任务,而软件和硬件在逻辑功能上又是等效的.
￼
一般来说, 提高硬件功能的比例可提高解题速度, 减少程序所需的存储空间, 但会增加硬件成本, 降低硬件利用率和计算机系统的灵活性以及适应性; 而提高软件功能的比例可降低硬件成本, 提高系统的灵活性、适应性, 但解题速度会下降, 软件设计费用和所需的存储器用量增加.
软硬件取舍的基本原则
原则1 应考虑在现有硬、器件条件下,系统要有高的性能价格比,主要从实现费用、速度和其他性能要求来综合考虑.
Dh约等于100Ds, Mh约等于100Ms, 
软件功能设计费用C * Ds, 软件功能的重复生产费用R * Ms

每台计算机硬件实现费用 Dh/V + Mh, 改为软件实现,则费用为C * Ds/V + R * Ms, 
只有当硬件实现费用小于软件实现费用时, 用硬件实现才是适宜的,当C和R比较大时,成立.只有经常要用的基本单元功能,才适宜用硬件实现.只有对产量大的计算机系统,增大硬件功能实现的比例才是适宜的.

Ds 约等于10000Ms, 只有产量大的计算机系统, 增大硬件功能实现的比例才是适宜的.

原则2 要考虑到准备采用和可能采用的组成技术,使之尽可能不要过多或不合理地限制各种组成、实现技术的采用.
原则3 不能仅从“硬”的角度考虑如何便于应用组成技术的成果和便于发挥器件技术的进展,还应从“软”的角度把如何为编译和操作系统的实现以及为高级语言程序的设计提供更多、更好的硬件支持放在首位.


定量设计原理: 哈夫曼(Huffman)压缩原理,Amdahl定律和程序访问的局部性定律
哈夫曼压缩原理: 尽可能加速处理高概率的事件远比加速处理概率很低的事件对性能的提高要显著.

Amdahl定律: 表明了性能提高量的递减规律, 如果只对系统中的一部分进行性能改进, 改进的越多, 整体性能提高的增量却越小.告诉我们,改进效果好的高性能系统应是一个个部分性能均能平衡得到提高的系统, 不能只是其中某个功能部件性能的提高.

系统加速比: 系统改进后的性能与未改进时的性能的比值,或系统未改进时的程序执行时间与改进后的程序执行时间的比值. 系统加速比与性能可改进比和部件加速比有关

程序访问的局部性包括时间上和空间上的两个局部性. 时间上的局部性指的是现在正在使用的信息可能不久还要使用,这是因为程序存在着循环. 空间上的局部性指的是最近的将来要用到的信息很可能与现在正在使用的信息在程序位置上是邻近的, 这是因为指令通常是顺序存放、顺序执行的, 数据也通常是以向量、阵列、树表等形式簇聚地存放在一起的.

计算机系统设计的主要任务和方法
主要任务: 包括系统结构、组成和实现的设计.
计算机系统设计首先要根据市场和应用情况, 确定用户对计算机系统的功能、性能和价格要求. 其中, 应用软件对功能的确定起主要作用.
1. 要弄清其应用领域是专用的还是通用的
2. 要弄清软件兼容是放在哪级层次
3. 要弄清对操作系统有何种要求
4. 要如何保证有高的标准化程度

设计方法: 由上往下,也称由顶向底设计(串行设计方法, 专用机);由下往上设计,也称由底向顶设计(串行设计, 是一种通用机设计方法); 从中间开始向两边设计(通用机一般采用的方法)

从中间开始向两边设计的过程: 从中间开始设计是选择从层次结构的主要软、硬界面开始设计, 即在传统机器语言机器级与操作系统机器级之间进行合理的软硬件功能分配. 同时, 考虑硬件能对操作系统、编译系统的实现提供什么样的支持. 然后由这个中间界面分别向上、向下同时进行软、硬件的设计. 软件人员依次设计操作系统级、汇编语言级、高级语言级和应用语言级; 硬件人员依次设计传统机器语言机器级、微程序机器级和数字逻辑级. 软件和硬件并行设计, 大大缩短了系统的设计周期, 设计过程中两部分人可交流协调, 适当微调软、硬件实现的比例.


软件的可移植性: 指的是软件不修改或者只经少量修改就可由一台机器移到另一台机器上运行,同一软件可应用于不同的环境,
实现软件移植的技术: 统一高级语言(应用于结构相同以至完全不同的机器之间高级语言程序的软件移植,很困难,但是有重要意义是必须解决的重要问题)、采用系列机(只能应用在结构相同或者相似的机器之间的汇编程序的软件移植)、模拟和仿真

模拟: 用机器语言程序解释实现软件移植的方法. 只适合移植运行时间短、使用次数少, 而且在时间关系上没有约束和受限制的软件.
仿真: 用微程序直接解释另一种机器指令系统的方法. 
仿真和模拟的主要区别在于解释用的语言, 仿真使用微程序解释, 其解释程序存储于控制存储器中; 而模拟是使用机器语言程序解释, 其解释程序存储于主存中.


模拟与仿真的选择: 不同系列间的软件移植一般是仿真和模拟并行, 频繁使用的易于仿真的机器指令宜用仿真,以提高速度; 很少使用的、难以仿真的指令及I/O操作宜用模拟.

统一高级语言可以解决结构相同或完全不同的机器间的软件移植, 从长远看是方向,但目前难以解决, 只能做相对统一. 系列机是当前普遍采用的方法, 但只能实现同一系列内的软件兼容, 虽然允许发展、变化,但兼容的约束反过来会阻碍系统结构取得突破性的进展. 模拟灵活, 可实现不同系统间的软件移植, 但结构差异太大时, 效率、 速度会急剧下降. 仿真在速度上损失小, 但不灵活, 只能在差别不大的系统间使用,否则效率也会过低且难以仿真, 需与模拟结合才行. 此外发展异种机联网也是实现软件移植的一种途径.

没有统一高级语言的原因:
1. 不同的用途要求语言的语法、语义结构不同
2. 人们对语言的基本结构看法不一
3. 即使同一种高级语言在不同厂家的机器上也不能完全通用
4. 受习惯势力阻挠, 人们不愿抛弃惯用的语言.

由于系列内个当机器从程序设计者角度看, 都具有相同的机器属性, 因此按此属性编制的机器语言程序及编译程序都能不加修改地通用于各档机器, 这种情况下的各档机器被称为是软件兼容的.

系列机软件必须保证向后兼容, 力争向前兼容.

应用发展对系统结构的影响:
1. 各种应用对结构设计会提出范围广泛的要求.
2. 随着应用领域的扩充, 应用要求的提高, 必然要求研制优化于这种应用的系统结构

计算机应用可归纳为向上升级的4类: 数据处理, 信息处理, 知识处理和智能处理. 

器件发展对系统结构的影响:器件的发展是推动结构和组成前进的关键因素.
1. 器件集成度的提高, 使器件的速度迅速提高, 机器主频和速度也有数量级的提高.
2. 器件可靠性有数量级的提高, 保证流水技术的实现.
3. 现场型PROM器件, 使微程序技术得以实现.
4. 高速相联存储器的实现, 促进相联处理机这种结构的发展, 推动向量机、数组机和数据库机的发展.

软件、应用、器件对计算机系统结构的发展有着很大的影响, 反过来, 计算机系统结构的发展又会对软件、应用、器件提出新的发展要求. 结构设计不仅要了解结构、组成、实现,还要充分了解软件、应用、器件的发展, 这样才能对计算机系统结构进行有效的设计、研究和探索.

并行性: 解题中具有可以同时进行运算或操作的特性, 包括同时性和并发性二重含义.
同时性: 指两个或多个事件在同一时刻发生.并发性指两个或多个事件在同一时间间隔内发生.
开发并行性的目的是为了能并行处理, 以提高计算机解题的效率.
并行性的不同等级:
* 系统执行程序的角度(低到高): 指令内部、 指令之间、 任务或进程之间、 作业或程序之间
* 系统中处理数据的角度(低到高): 位串字串、位并字串、位片串字并、全并行 
* 计算机信息加工的各个步骤和阶段的角度: 存储器操作并行、处理器操作步骤并行、处理器操作并行、指令/任务/作业并行

并行性开发的途径: 时间重叠、资源重复和资源共享
时间重叠是在并行性概念中引入时间因素, 让多个处理过程在时间上相互错开, 轮流重叠使用同一个硬件设备的各个部分, 加快硬件周转来赢得速度.
资源重复是在并行概念中引入空间因素, 通过重复设置硬件资源来提高可靠性或性能.
资源共享是用软件方法, 让多个用户按一定时间顺序轮流使用同一套资源来提高资源利用率, 相应地也就提高了系统的性能.

多机系统的耦合度: 最低耦合、 松散耦合和紧密耦合

计算机系统分类
	1966弗林,按指令流和数据流的多倍性分类: 单指令流单数据流(SISD)、单指令流多数据流(SIMD)、多指令流单数据流(MISD)和多指令流多数据流(MIMD)
￼
	1978 美国的库克, 用指令流和执行流及其多倍性分类: 单指令流单执行流(SISE)、单指令流多执行流(SIME)、多指令流单执行流(MISE)和多指令流多执行流(MIME).
	1972 美籍华人冯泽云, 用数据处理的并行度分类: 字串位串(WSBS)、字串位并(WSBP)、字并位串(WPBS)和字并位并(WPBP) .

数据表示、寻址方式与指令系统

数据表示指的是能由计算机硬件识别和引引用的数据类型, 表现在它有对这种类型的数据进行操作的指令和运算部件.

数据结构是要通过软件映像, 变换成计算机中所具有的数据表示来实现的. 不同的数据表示可为数据结构的实现提供不同的支持,表现为实现效率和方便性的不同, 数据结构和数据表示是软、硬件的交界面. 数据表示的确定实质上是软、硬件的取舍.

早期计算机只有定点数据表示,浮点数需要用两个定点数分别表示其阶码和尾数.
20世纪50年代,提出的变址操作,为向量、阵列数据结构的实现提供了直接支持.

高级数据表示: 
	自定义数据表示: 标志符数据表示和数据描述符
		
￼
标志符数据表示: 每个数据都带有类型标志, 数据类型与数据本身直接联系在一起,这种数据表示称为标志符数据表示.
标志符的主要优点: 
    1. 简化指令系统和程序设计
    2. 简化编译程序
    3. 便于实现一致性校验
    4. 能由硬件自动变换数据类型
    5. 支持数据库系统的实现与数据类型无关的需求, 使程序不用修改即可处理多种不同类型的数据.
    6. 为软件调试和应用软件开发提供了支持.
标志符可能带来的问题:
    1. 每个数据字因增设标志符, 会增加程序所占的主存空间.但只要合理设计,这种增加量是很小的,甚至有可能减少, 因为指令种类减少, 缩短了操作码位数.
    2. 采用标志符会降低指令的执行速度.
	
	为进一步减少标志符所占的存储空间, 对向量、数组、记录等数据, 由于元素属性相同, 因此发展出数据描述符.
	数据描述符和标志符的差别在于标志符是和每个数据相连的, 合存在一个存储单元中, 描述单个数据的类型特征; 数据描述符则是与数据分开存放, 用于描述所要访问的数据是整块的还是单个的, 访问该数据块或数据元素所要的地址以及其他信息等
	
	向量、数组数据表示
		有向量数据表示的处理机就是向量处理机, 如向量流水机、阵列机、相联处理机等

	堆栈数据表示
		堆栈数据结构在编译和子程序调用中很有用, 为高效实现, 不少计算机都设有堆栈数据表示, 有堆栈数据表示的计算机称为堆栈计算机.
	堆栈计算机表现:
    1. 由高速寄存器组成的硬件堆栈, 并附加控制电路, 与主存中的堆栈区在逻辑上构成整体, 使堆栈的访问速度是寄存器的, 容量是主存的.
    2. 有丰富的堆栈操作指令且功能很强
    3. 有力地支持了高级语言程序的编译
    4. 有力地支持子程序的嵌套和递归调用.

引入数据表示的原则:
1. 看系统的效率是否有显著提高, 包括实现时间和存储空间是否有显著减少.
2. 看引入这种数据表示后, 其通用性和利用率是否提高.

浮点数尾数基值大小和下溢处理方法的选择

￼
阶值位数p: 主要影响两个可表示区的大小, 即可表示数的范围大小
尾数位数m: 主要影响在可表示区中能表示值的精度.
当阶值位数p 一定时，尾数采用什么进制都会影响到数 的可表示范围、精度及数在数轴上分布的离散程度

 
￼

￼
所谓规格化正尾数, 就是正尾数小数点后的第1个rm进制数位不是0的数.

可表示数的范围: 随Rm增大，可表示数的范围增大
可表示数的个数: 随着Rm增大, 可表示数的个数增多.
数在数轴上的分布: Rm越大, 数的密度分布越稀
可表示的精度: rm越大, 数在数轴上的分布越稀, 精度自然就下降.
运算中的精度损失: rm越大, 尾数右移的机会越小, 精度的损失就越小.
运算速度: rm增大时, 由于对阶或尾数溢出需右移及规格化需左移的次数减少, 运算速度可以提高.

尾数基值取大,会扩大浮点数的表示范围, 增加可表示数的个数, 减少移位次数, 降低右移造成的精度损失和提高运算速度, 但也会降低数据的表示精度,数值的分布变稀. 

浮点数尾数下溢处理方法: 截断法、 舍入法、恒置“1”法、查表舍入法
￼
￼

寻址方式: 面向主存、面向寄存器和面向堆栈的寻址方式.
面向主存的寻址方式主要是访问主存, 少量访问寄存器. 面向寄存器的寻址主要访问寄存器, 少量访问主存和堆栈. 面向堆栈的寻址主要访问堆栈,少量访问主存或寄存器.

寻址方式在指令中有两种不同的指明方式: 一种方式是占用操作码中的某些位来指明. 另一种是不占用操作码, 而是在地址码部分专门设置寻址方式位字段指明.
优缺点:第一种方式的优点是操作码和寻址方式的总位数较短, 但是不灵活; 第二种方式寻址灵活, 但是操作码和寻址方式位的总位数长.

逻辑地址是程序员编程用的地址. 主存物理地址是程序在主存中的实际地址.
程序在主存中的定位技术: 静态再定位、动态再定位、 虚实地址映像表
静态再定位:  利用Von Nenumann型机器指令可修改的特点, 在目的程序装入主存时, 由装入程序用软件方法把目的程序的逻辑地址变成物理地址, 程序执行时, 物理地址不再改变.(20世纪60年代提出程序指令不修改)
动态再定位: 在执行每条指令时才形成访存物理地址的方法 (因为不是直接取指令地址码,是经地址硬件变换形成,为防止出错,要判断是否有效)

变址寻址是对诸如向量、数组等数据块运算的支持, 以便于实现程序的循环. 基址寻址是对逻辑地址空间到物理地址空间变换的支持. 以利于实现程序的动态再定位. 所以, 基址寻址和变址寻址都会同时用到. 基址寻址将装入程序形成物理地址改成由地址加法器硬件形成, 加快了地址变换的速度.

虚实地址映像表: 地址加界法要求程序员所用编址空间不能超出实际主存的容量, 20世纪70年代,采用虚拟存储器增加了映像表硬件后, 使程序空间可以超过实际主存空间, 进一步发展了动态再定位技术,

信息在存储器中按整数边界存储: 为了使任何时候所需的信息都只用一个存储周期访问到, 要求信息在主存中存放的地址必须是该信息宽度(字节数)的整数倍.
信息在存储器中按整数边界存储对于保证访问速度是必要的, 但是会造成空间的某些浪费.这是速度和价格的权衡, 随着主存器件价格的不断下降,主存容量显著增大,为了保证访问速度, 现在提出信息在存储器中必须按整数边界存储就非常必要了.


指令系统的设计和优化

指令系统是程序设计者看计算机的主要属性, 是软、硬件的主要界面, 它在很大程度上决定了计算机具有的基本功能
指令系统设计的基本原则:
设计和确定指令系统主要应考虑如何有利于满足系统的基本功能, 有利于优化计算机的性能价格比, 有利于指令系统今后的发展和改进.

指令类型一般分为非特权型和特权型两类. 特权型指令只供系统程序员使用, 用户无权使用.

指令系统的设计包括指令的功能(操作类型、寻址方式和具体操作内容)和指令格式的设计.
在设计指令系统时, 编译程序设计者和系统结构设计者的要求是有比较大的差异.
编译程序设计者要求指令系统应设计具有: 规整性、对称性、独立性和全能性、正交性、可组合性、可扩充性.
系统结构设计者则还希望: 指令码密度适中、兼容性、适应性.
总之指令系统的设计应能同时协调兼顾编译程序设计者和系统结构设计者两者的要求.


指令是由操作码和地址码两部分组成.
哈夫曼压缩概念的基本思想: 当各种事情发生的概率不均等时, 采用优化技术, 对发生概率最高的事件用最短的位数来表示, 而对出现概率较低的事件允许用较长的位数来表示, 就会使表示的平均位数缩短.

研究操作码的优化表示主要是为了缩短指令字长, 减少程序总位数及增加指令字能表示的操作信息和地址信息.

定长操作码, 扩展操作码, 完全哈夫曼编码.

指令字格式优化的措施:
1. 采用扩展操作码, 并根据指令的频度pi的分布状况选择合适的编码方式, 以缩短操作码的平均码长
2. 采用多种寻址方式, 以缩短地址码的长度, 并在有限的地址长度内提供更多的地址信息.
3. 采用多种地址制, 以增强指令的功能
4. 在同种地址制内再采用多种地址形式. 
5. 在维持指令字在存储器中按整数边界存储的前提下, 使用多种不同的指令字长度.


指令系统的发展和改进
两种途径和方向(CISC和RISC)

复杂指令系统计算机 CISC（Complex Instruction Set Computer）
* 	面向目标程序的优化实现改进：
		途径1 通过对大量已有机器的机器语言程序机器执行情况，统计各种指令和指令串的使用频度来加以分析和改进
		途径2 增设强功能复合指令来取代原先由常用宏指令或子程序实现的功能
* 	面向高级语言的优化实现改进
		途径1 通过对源程序中各种高级语言语句的使用频度进行统计来分析改进。
		途径2 如何面向编译，优化代码生成来改进。
		途径3 改进指令系统，使它与各种语言间的语义差距都有同等的缩小
		途径4 提出采用让计算机具有分别面向各种高级语言的多种指令系统、多种系统结构的面向问题动态自寻优的计算机系统。
		途径5 发展高级语言计算机
* 	面向操作系统的优化实现改进
		途径1 通过对操作系统中常用指令和指令串的使用频度进行统计分析来改进。
		途径2 考虑如何增设专用与操作系统的新指令。
		途径3 把操作系统中频繁使用的，对速度影响大的机构行软件子程序硬化或固化，改为直接使用硬件或微程序解释实现
		途径4 发展让操作系统由专门的处理机来执行的功能分布处理系统结构

CISC存在的问题：
1. 	指令系统庞大
2. 	许多指令操作复杂，执行速度很低
3. 	由于指令系统庞大，使高级语言编译程序选择目标指令的范围太大
4. 	由于指令系统庞大，各种指令的使用频度都不会太高，相当一部分指令的利用率很低
	

精简指令系统计算机 RISC（Reduced Instruction Set Computer）
设计RISC的基本原则：
1. 只选用使用频度很高的那些指令，增加少量能有效支持操作系统、高级语言实现及其他功能的指令
2. 减少指令系统所用寻址方式种类，一般不超过两种
3. 让所有指令都在一个机器周期内完成
4. 扩大通用寄存器，尽量减少访存
5. 为提高指令执行速度，大多数指令都用硬联控制实现，少数指令使用微程序
6. 通过精简指令和优化设计编译程序，简单有效地支持高级语言的实现
设计RISC结构采用的基本技术
1. 按设计RISC的一般原则来设计
2. 逻辑实现采用硬联和微程序相结合
3. 在CPU中设置大量工作寄存器并采用重叠寄存器窗口
4. 指令用流水和延迟转移
5. 采用高速缓冲存储器Cache， 设置指令Cache和数据Cache分别存放指令和数据
6. 优化设计编译系统
设计高质量的编译程序，有效地提高计算机性能是RISC系统设计的关键之一

RISC技术的好处：
* 简化指令系统设计
* 提高计算机的执行速度和效率
* 降低设计成本，提高系统的可靠性
* 可直接支持高级语言的实现，简化编译程序的设计
RISC技术存在的问题和不足：
* 加重了汇编语言程序设计的负担（由于指令少，某些CISC指令需要多条RSIC指令才能完成），增加了机器语言程序的长度，占用存储空间多，加大了指令的信息流量
* 对浮点运算的执行和虚拟存储器的支持虽有很大加强，但仍显得不足
* RISC计算机的编译程序比CISC的难写

存储、中断、总线与I/O系统

对存储系统的基本要求是大容量、高速度和低价格.
最大频宽和实际频宽: 单体的Bm = W/TM,m个存储体并行的最大频宽Bm = W*m/TM, 实际频宽往往低于最大频宽.
计算机系统总希望存储器速度能和CPU匹配, 使CPU的高速性能得以发挥, 容量上能放下所有系统软件及多个用户软件. 
￼

能并行读出多个CPU字的单体多字和多体单字、多体多字的交叉访问主存系统被称为并行主存系统.

￼
提高模m值, 是能提高主存系统的最大频宽, 但主存实际频宽并不是随m值增大而线性提高.当转移概率一定时, 提高模数m对提高主存实际频宽的影响已经不显著了, 进一步增大反而会因为工程实现上的问题,导致性能更低,价格更高.


中断:  CPU中止正在执行的程序, 转去处理随机提出的请求, 待处理完后, 再回到原先被打断的程序继续恢复执行的过程.
中断系统,:响应和处理各种中断的软、硬件总体
中断分为: 内部中断、 外部中断和软件中断

内部中断: 由CPU内的异常引起; 外部中断: 由中断信号引起; 软件中断由自陷指令引起, 用于供操作系统服务.
外部中断又分为: 可屏蔽中断和不可屏蔽中断.

引起中断的各种事件称为中断源. 中断源向中断系统发出请求中断的申请, 称为中断请求. 
中断分类的依据: 是把中断源性质相近、中断处理过程类似的归为同一类
中断分类的目的: 减少中断处理程序的入口; 每一类给一个中断服务程序总入口, 可以减少中断服务程序入口地址形成的硬件数量.
中断分类: 机器校验、管理程序调用、程序性、外部、输入/输出和重新启动
中断和异常: 由执行现行指令引起的暂停事件, 如运算结果溢出、页面失效等属于异常,一般不能屏蔽, 应予立即响应和处理. 中断则专指那些与当前进程运行无关的请求暂停的事件, 如机器故障中断请求、 外设中断请求、定时器中断请求等. 中断可以被屏蔽, 未被响应的中断源保留在中断字寄存器中, 直至屏蔽接触后仍可得到响应和处理.

中断的分级: 不同类的中断要根据中断的性质、紧迫性、重要性以及软件处理的方便性把它们分成不同的级别. 中断系统按照中断源的级别高低来响应.

机器校验列为第1级, 程序性中断和管理程序调用一般列为第2级, 外部中断级别高于输入/输出中断级别, 重新启动中断级别一般最低.
IBM370中断响应的优先次序为: 紧急的机器校验、 管理程序调用和程序性、可抑制的机器校验、 外部、输入/输出、重新启动.
￼
￼

中断系统的功能包括中断请求的保存和清除、优先级的确定、中断断点及现场的保存、对中断请求的分析和处理以及中断返回等. 中断系统主要是要有高的中断响应速度, 其次是中断处理的灵活性, 因此中断系统的软、硬件功能分配实质上是中断处理程序软件和中断响应硬件的功能分配
最初为了简化硬件、降低成本, 中断系统的大部分功能都是由软件完成的, 后来改用中断响应排队器硬件实现, 中断的分析也由程序查询改为硬件编码,
中断现场包括软件状态和硬件状态.

总线是用于互连计算机、CPU、存储器、I/O接口及外围设备、远程通信设备间信息传送通路的集合. 
总线与其相配合的附属控制电路统称为总线系统.
数据线根数决定同时传送的数据位数, 即数据通路宽度,

总线按在系统中的位置分芯片级、板级和系统级

就总线允许信息传送的方向来说, 可以有单向传输和双向传输两种, 双向传输又有半双向和全双向的不同.

总线按用法可分为专用和非专用两类: 只对接一对物理部件的总线称专用总线


总线控制方式: 集中式控制, 分布式总线控制
优先次序的确定可以有串行链接、定时查询和独立请求
串行链接
	1. 优点: 选择算法简单, 用于解决总线控制分配的控制线的线数少,只需要3根,且不取决于部件的数量.部件增减容易,由于逻辑简单,容易通过重复设置提高可靠性.
	2. 缺点: 对“总线可用”线及其有关电路的失效敏感; 由于优先级是线连固定, 不能由程序改变,不灵活,  

￼

定时查询
1. 优点: 因计数器初值、部件均可由程序制定, 优先次序可用程序控制,灵活性强; 不会因为某个部件失效而影响其他部件对总线的使用, 可靠性高
2. 缺点是: 控制线的线数较多, 需要 2+ [log2N]根, 可以共享总线的部件数受限于定时查询线的线数,扩展性稍差; 控制较为复杂; 总线分配的速度取决于计数信号的频率和部件数, 不能很高.
￼
独立请求
1. 优点: 总线分配速度快, 所有部件的总线请求同时送到总线控制器, 不用查询; 控制器可以使用程序可控的预定方式、自适应方式、循环方式或它们的混合方式灵活确定下一个使用总线的部件;能方便地隔离失效部件的请求;
2. 缺点: 控制线数量过大, 为控制N个设备必须有2N+1根控制线, 而且总线控制器要复杂的多
￼


集中式控制的3种方式各有优缺点, 后两种方式用在高性能的巨、大、中型计算机上, 而目前用的最广泛的小、微型机上主要还是采用串行链接方式.

总线的通信技术:
信息在总线上的传送方法基本可以分为同步和异步两种

异步通信又分单向源控制和请求/回答双向控制两种: 通信过程只由源或目的部件之一控制的称为单向源控式或单向目控式, 而由源和目的共同控制的称为请求/回答双向控制
单向源控式的优点是简单、高速. 缺点是: 没有来自目的部件指明传送是否有效的回答; 不同速度的部件间通信比较困难, 部件内需设置缓冲器以缓冲来不及处理的数据; 效率低, 高速部件难以发挥其效能; 要求“数据准备”干扰小, 否则易误认成有效信号.
单向控制的缺点是: 不能保证下一个数据传送之前让所有数据线和控制线的电平信号恢复成初始状态, 从而可能造成错误.


数据宽度与总线线数
数据宽度是I/O设备取得I/O总线后所传送数据的总量.与数据通路宽度不同. 数据通路宽度是数据总线的物理宽度, 即一个时钟周期所传送的信息量.
数据宽度有: 单字、定长块、可变长块、单字加定长块和单字加可变长块等之分
单字宽度适合于输入机、打印设备等低速设备.
定长块宽度适合于磁盘等高速设备.
可变长块宽度适合于高优先级的中高速磁带、磁盘等设备,
对于挂有速度较低而优先级较高的设备的总线,可以采用单字加定长块传送.采用单字加可变长块的传送, 是一种灵活有效却复杂、开销大的方法.

数据总线的宽度: 位、 字节、 字或双字
在满足性能的前提下应尽量减少线数, 总线线数可通过用线的组合、 编码以及并/串-串/并转换来减少, 但一般会降低总线的流量.
总线标准一般包括机械、功能、电气及过程4个方面的标准.

I/O系统
I/O系统包括输入/输出设备、 设备控制器及与输入/输出操作有关的软、硬件.
输入/输出系统的发展经历了3个阶段, 相对应于3种方式, 即程序控制I/O(包括全软件的、程序查询的、中断驱动的)、直接存储器访问(DMA)及I/O处理机方式.

对于I/O处理机方式, 又有通道(Channel)方式和外围处理机(PPU)方式.
输入/输出设备分外存和传输设备两大类.

根据通道数据传送期中信息传送方式的不同, 可分为字节多路、 数组多路和选择3类通道
字节多路通道适用于连接大量的像光电机等字符类低速设备.传送一个字符时间很短, 但字符间的等待时间很长
数组多路通道适合于连接多台磁盘等高速设备.传送速率很高, 但传送开始前的寻址辅助操作时间很长.
选择通道适合于连接优先级高的磁盘等高速设备.独占通道, 只能执行一道通道程序.

通道流量的设计

通道流量是通道在数据传送期内, 单位时间内传送的字节数. 它能达到的最大流量称通道极限流量,
￼

通道实际最大流量
￼
通道的实际最大流量不超过通道的极限流量
￼
宏观上保证不丢失:为保证通道上满负荷的最坏情况下都不丢失信息, 必须满足设备要求通道的实际最大流量不超过通道极限流量. 
微观上保证不丢失: 在设备或设备控制器中设置一定容量的缓冲器, 或采用可动态提高低速设备的响应优先级来保证从微观上也不丢失信息.


存储体系

基本的二级存储体系是虚拟存储器和Cache存储器, 这是存储体系的两个不同的分支.
虚拟存储器是因为主存容量满足不了要求而提出来的. 在主存和辅存之间, 增设辅助的软硬件设备, 构成整体, 所以也称主存-辅存存储层次,速度是接近主存的, 容量是辅存, 价格接近辅存.

应用程序员可用机器指令的地址对整个程序统一编址, 称该地址为虚地址, 而把实际主存地址称为实地址. 只要是存储层次, 都必须对应用程序员透明.
￼

Cache存储器是因为主存速度满足不了需求而引出的. 在CPU和主存增设高速、小容量、每位价格较高的Cache, 用辅助硬件将Cache和主存构成整体. 有接近于Cache的速度、主存的容量, 接近于主存的每位价格. Cache存储器不仅对应用程序员透明,对系统程序员也是透明的.

￼
￼

为了使存储体系能有效地工作, 当CPU要用到某个地址的内容时, 总希望它已在速度最快的M1中, 这就要求能预知未来被访问信息的地址,
存储层次构成的主要依据: 能预知未来被访问信息的地址,这种预知的可能性是基于计算机程序具有局部性,包括时间上的局部性和空间上的局部性.
 
预知的准确性是存储层次设计好坏的主要标志, 很大程度上取决于所用算法和地址映像变换的方式.

存储体系的性能参数: 每位价格c、命中率H和等效访问时间TA.

虚拟存储器通过增设地址映像表机构来实现程序在主存中的定位.
虚拟存储器的管理方式: 段式、页式和段页式.
将主存按段分配的存储管理方式称为段式管理.为了进行段式管理, 每道程序在系统中都有一个段表来存放该道程序各段装入主存的状况信息.

￼
段式存储缺点:地址字段和段长字段都很长, 增加辅助硬件开销,降低查表速度, 主存管理麻烦, 还会带来大的段间零头浪费.

页式存储是把主存空间和程序空间都机械地等分成固定大小的页, 按页顺序编号.

￼

页式对应用程序员完全透明, 所需映像表硬件较少, 地址变换的速度快,调入操作简单. 但页式不能完全消除主存可用区的零头浪费, 因为程序大小不可能恰好就是页面大小的整数倍, 产生的页内零头虽然无法利用,但是比段式要小的多, 所以在主存空间利用率上, 页式优于段式.段式各段独立,更灵活, 

段页式存储是把实(主)存机械地等分成固定大小的页, 程序按模块分段, 每段又分成与实主存页面大小相同的页.

￼

页式虚拟存储器是采用页式存储和管理的主存-辅存存储层次.

当处理机要用到的指令或数据不在主存中时, 会产生页面失效, 这时需要去辅存中将含该指令或数据的一页调入主存.通常虚存空间比主存空间大得多, 必然会出现主存已满又发生页面失效的情况, 这时将辅存的一页调入主存会发生实页冲突.
替换算法的确定主要看主存是否有高的命中率, 也要看算法是否便于实现, 辅助软、硬件成本是否低.
已研究过的多种替换算法: 随机算法(RAND)、先进先出算法(FIFIO)、近期最少使用算法(LRU)等

命中率与所选用替换算法有关, 命中率与分配给程序的主存页数有关.
堆栈型替换算法: LRU、OPT

对页面失效如何处理是设计好页式虚拟存储器的关键之一. 页面失效不能按一般的中断对待, 应看作是一种故障, 必须立即响应和处理.页面失效后还应解决如何保存好故障点现场以及故障处理完后如何恢复故障点现场, 以便能继续执行这条指令.

等效访问速度提高, 既要有很高的主存命中率,又要有尽可能短的访主存时间
高的主存命中率受很多因素影响, 包括页地址流、页面调度策略、替换算法、页面大小、分配给程序的页数(主存容量)等.

命中率是评价存储体系性能的重要指标, 程序地址流、替换算法以及分配给程序的实页数不同都会影响命中率.

高速缓冲(Cache)存储器是为弥补主存速度的不足, 在处理机和主存之间设置一个高速、小容量的Cache, 构成Cache-主存存储层次. 使之从CPU角度来看, 速度接近于Cache, 容量却是主存的.

地址的映像与变换: 全相联映像和变换、直接映像和变换、组相联映像及其变换
全相联映像: 主存中任意一块都可映像装入到Cache中任意一块. 优点是块冲突概率最低, 只有当Cache全部装满才可能出现块冲突, 所以cache的空间利用率最高. 但容量大,成本高, 且当容量很大时, 查表速度很难提高.
￼
￼
直接映像及其变换: 把主存空间按Cache大小等分成区, 每区内的各块只能按位置一一对应到Cache的相应块位置上. 优点是节省所需硬件, 只需要容量较小的按地址访问的区号标志表存储器和少量外比较电路,成本很低.缺点是Cache的块冲突概率很高, Cache空间利用率低.
￼
￼
组相联映像: 各组之间是直接映像, 而组内各块之间是全相联映像.
组相联映像比全相联映像在成本上要低得多, 而性能上仍可接近于全相联映像,
￼

Cache存储器的地址变换和块替换算法是全硬件实现的, 因此Cache存储器对应用程序员和系统程序员都是透明的,而且Cache对处理机和主存之间的信息交往也是透明的. 
解决因中央处理机写Cache使主存内容跟不上Cache对应内容变化造成不一致问题的关键是选择好更新主存内容的算法. 一般有写回法和写直达法两种, 
写回法也称为抵触修改法. 是在CPU执行写操作时, 信息只写入Cache, 仅当需要替换时, 才将改写过的Cache块先写回主存, 然后在调入新块.
写直达法也称存直达法,是利用Cache存储器在处理机和主存之间的直接通路, 每当处理机写入Cache的同时, 也通过此通路直接写入主存.
写回法把开销花在每次都要替换的时候, 写直达法是把开销花在每次写Cache时都要增加一个比写Cache时间长得多的写主存时间. 
写回法和写直达法都需要有少量缓冲器.
采用写回法的有Amdahl的所有计算机和IBM3081; 采用写直达法的有IBM370/168、IBM3033、PDP-11/70、VAX-11/780、Honeywell66/60和Honeywell66/80

对于共享主存的多CPU系统, 绝大多数还是采用各个CPU都有自己的Cache.保证各个Cache的内容一致,  一种解决办法是采用播写法,另一种办法是控制某些共享信息不得进入Cache. 还有一种办法是目录表法.

Cache预取算法: 恒预取和不命中时预取;

与虚拟存储器中的类似, 评价cache存储器的性能主要看命中率的高低, 而命中率与块的大小、 块的总数(即Cache的总容量)、采用组相联时组的大小(组内块数)、替换算法和地址流的簇聚性有关

三级存储体系: 物理地址Cache, 虚地址Cache, 全Cache
物理地址cache是由“Cache-主存”和“主存-辅存”两个独立的存储层次组成.
￼
虚地址Cache是将cache-主存-辅存直接构成三级存储层次形式, 
￼

全Cache是最近出现的组织形式, 没有主存, 只用Cache与辅存中的一部分构成“Cache-辅存”存储体系
￼

标量处理机
加快标量处理机的机器语言的解释是组成设计的基本任务, 可以从两方面实现, 
一是通过选用更高速的器件, 采取更好的运算方法, 提高指令内各微操作的并行程度,  减少解题过程所需要的拍数等措施, 加快每条机器指令的解释. 
二是通过控制机构同时解释两条、多条以至整段程序的方式, 加快整个机器语言程序的解释. 重叠和流水是其中常用的方式.

解释一条机器指令的微操作可归并成取指令、分析和执行
￼

指令的重叠解释使机器语言程序的执行速度会比采用顺序解释的有较大的提高.
顺序解释指的是各条指令之间顺序串行地进行,每条指令内部的各个微操作也顺序串行地进行.                                                                            
顺序解释的优点是控制简单, 转入下条指令的时间易于控制. 但缺点是上一步操作未完成, 下一步操作便不能开始, 速度上不去, 各部件利用率低
指令的重叠解释是在解释第k条指令的操作完成之前, 就可以开始解释第k+1条指令.
重叠解释不能加快一条指令的解释, 却能加快相邻两条指令以至整段程序的解释.
￼

实现指令的重叠解释必须在计算机组成上满足:
1. 要解决访主存的冲突: 需要让“取指k+1”与“分析k”在时间上重叠. 一种让操作数和指令分别存放于两个独立编址且可同时访问的存储器中, 有利于实现指令的保护, 但是增加了主存总线控制的复杂性以及软件设计的麻烦. 另一种是仍维持指令和操作数混存, 但采用多体交叉主存结构, 有一定的局限性. 第三种是增设采用先进先出方式工作的指令缓冲寄存器(简称指缓).
2. 要解决“分析”与“执行”操作的并行: 硬件上设置独立的指令分析部件和指令执行部件.
3. 要解决“分析”与“执行”操作控制上的同步: “一次重叠解释”, 指令分析部件和指令执行部件任何时候都只有相邻两条指令在重叠解释.
4. 要解决指令间各种相关的处理: 
￼
相关处理: 
1. 转移指令的处理: 当程序遇到条件转移, 一旦转移成功,重叠解释实际变成了顺序解释. 重叠效率会显著下降, 因此应减少使用条件转移指令, 或者使用延迟转移技术.
￼
2. 指令相关的处理: 指令相关是因为机器指令允许修改而引出的, 可以规定不允许修改, 但是不灵活,可以设置一条“执行”指令来解决.
￼
3. 主存空间数相关的处理: 主存空间数相关是相邻两条指令之间出现对主存同一单元要求先写而后读的关联.可以推后“分析k+1”的读. 推后读常见的方法是由存控(存储控制器)给读数、写数申请安排不同的访存优先级来解决. 在存控中将写数级别安排高于读数级别.
￼
4. 通用寄存器组相关的处理: 分为操作数的相关和变址值或基址值的相关两种,
    1. 解决通用寄存器组数相关的问题: 一种办法是可以与前述处理主存空间相关数一样,推后读“分析k+1”到“执行k”结束时开始, 也可以推后到“执行k”把结果送入L3, 然后再由“分析k+1”在取L1或L2时能取到即可.前者只要发生数相关就使一次重叠变成了完全的顺序串行, 速度明显下降; 采用后者则发生数相关时, 相邻两条指令的解释仍有部分重叠, 可以减少损失, 但控制复杂 .推后“分析k+1”和设置“相关专用通路”是解决重叠方式相关处理的两种基本方法.前者是以降低速度为代价的, 使设备基本上不增加; 后者是以增加设备为代价, 使重叠效率不下降. 若相关概率低, 则不宜采用“相关专用通路”,节省设备,重叠效率也不会明显下降.
    2. 解决通用寄存器组基址值或变址值的相关问题: 也有推后分析和设置专用通路两种


如果一次重叠方式解释指令仍达不到速度要求, 可采用同时解释多条指令的流水方式.流水与重叠在概念上没有差别, 流水可以看成是重叠的引申, 二者的差别只在于“一次重叠”是把一条指令的解释分为两个子过程, 而流水是分为更多个子过程.
￼
流水的分类: 依据向下扩展和向上扩展的思路. 向下扩展指的是把子过程进一步地细分.  向上扩展可理解为在多个处理机之间的流水.

流水按处理的级别可分为部件级、处理机级和系统级.
部件级:是指构成部件内的各个子部件间的流水; 处理机级: 是指构成处理机的各部件之间的流水; 系统级:指的是构成计算机系统的多个处理机之间的流水, 也称为宏流水.

从流水线具有功能的多少, 可以分为单功能流水线和多功能流水线.
单功能流水线只能实现单一功能的流水; 多功能流水线指的是同一流水线的各个段之间可以有多种不同的连接方式, 以实现多种不同的运算或功能.

按多功能流水线的各段能否允许同时用于多种不同功能连接流水, 可以把流水线分为静态流水线和动态流水线.
静态流水线在某一时间内各段只能按一种功能连接流水, 只有等流水线全部流空之后, 才能切换成按另一种功能连接流水.要求程序员编制出的程序应尽可能调整成有更多相同运算的指令串, 以提高其流水的效能.
动态流水线的各功能段在同一时间内可按不同运算或功能连接. 控制复杂, 成本高.
￼
从软、硬件功能分配的观点上看, 静态流水线是把功能负担较多地加到软件上, 以简化硬件控制; 动态流水线则是把功能负担较多地加到硬件控制上, 以提高流水线的效能.

从计算机所具有的数据表示角度, 可以把流水线处理机分为标量流水机和向量流水机.
标量流水机没有向量数据表示, 只能用标量循环方式来处理向量和数组. 向量流水机是向量数据表示和流水技术的结合

从流水线种各功能段之间是否有反馈回路的角度, 可以把流水线分为线性流水线和非线性流水线.
流水线各段串行连接, 各段只经过一次, 没有反馈回路的, 称为线性流水线;流水线除有串行连接的通路, 还有反馈回路, 使任务流经流水线需多次经过某个段或越过某些段, 则称为非线性流水线.

标量流水处理机的性能主要是吞吐率Tp、加速比Sp和效率n.

吞吐率和加速比: 吞吐率是流水线单位时间里能流出的任务数或结果数;
最大吞吐率受限于流水线中最慢子过程经过的时间, 流水线中经过时间最长的子过程称为瓶颈子过程
￼
为了提高流水线的最大吞吐率,首先要找出瓶颈, 然后设法消除瓶颈. 消除瓶颈的一种办法是瓶颈子过程再细分.另一种是可以通过重复设置多套瓶颈段并联, 让它们交叉并行,瓶颈子过程并联, 要解决好各并行子过程之间的任务分配和同步控制, 比瓶颈子过程再细分控制要复杂, 设备量要多.
￼
￼

流水线的实际吞吐率总比最大吞吐率要小.
￼
￼

￼
效率:是指流水线中设备的实际使用时间占整个运行时间之比, 也称流水线设备的时间利用率.
￼
￼
流水线最适合解具有统一操作类型, 且输出与输入之间没有任何联系和相关的一串运算.只要能连续给流水线提供输入数据, 就能使流水线不间断地流动.当n值很大时, 流水线的效率就可接近于1, 实际吞吐率就可接近于最大吞吐率.

转移指令和其后的指令之间存在关联, 使之不能同时解释, 其造成的对流水机器的吞吐率和效率下降的影响要比指令相关、主存操作数相关和通用寄存器组数相关以及基址值或变址值相关严重的多, 所以被称为全局性相关. 而后者只影响相关的两条或几条指令, 最多影响流水线某些段工作的推后, 不会改动指缓中预取到的指令, 影响是局部的, 所以被称为局部性相关.

标量流水机的相关处理:局部性相关处理、全局性相关处理、流水机器的中断处理、非线性流水线的调度


局部性相关: 指令相关、访存操作数相关和通用寄存器组数相关等局部性相关都是由于在机器同时解释的多条指令之间出现了对同一主存单元或寄存器要求“先写后读”. 推后读和设置相关直接通路.

任务在流水线流动顺序的安排和控制可以有两种方式: 一种是让任务流水流水线的顺序保持与流入流水线的顺序一致, 称为顺序流动方式或同步流动方式, 另一种是让流出流水线的任务顺序可以和流入流水线的顺序不同, 称为异步流动方式.
异步流动: 先写后读相关、写-写相关(对同一单元要求在先的指令先写入, 在后的指令才写入的关联)、先读后写相关(对同一单元要求在先的指令先读出, 在后的指令才写入的关联). 写-写相关和先读后写相关只有在异步流动时才有可能发生.

流水线中可以通过设置相关直接通路来减少吞吐率和效率的损失,但是会使硬件耗费大, 控制复杂, 因此一般宜采用分布式控制和管理, 并设置公共数据总线, 以简化各种相关的判别和实现相关直接通路的连接.

公共数据总线是一种总线方式的相关直接通路, 可以为多种和多个不同相关所共用, 通过给出不同站号来控制其不同连接.
标量流水机对局部性相关的处理一般采用总线式分布控制管理, 包括: 一是相关的判断主要是靠分布于各寄存器的“忙位”标志来管理; 二是在分散于各流水线的入、出端处设置若干保存站来缓存信息; 三是用站号控制公共数据总线的连接作相关专用通路, 使之可为多个子过程的相关所共用; 四是一旦发生相关, 用更换站号来推后和控制相关专用通路的连接; 五是采用多条流水线, 每条流水线入端有多组保存站, 以便发生相关后, 可以采用异步的流动方式.

全局性相关指的是已进入流水线的转移指令(尤其是条件转移指令)和其后续指令之间的相关.
处理方法: 使用猜测法、加快和提前形成条件码、采取延迟转移、加快短循环程序的处理

使用猜测法时保证猜错时可恢复分支点原先的现场方法: 
1. 应当与正常情况下的指令解释不同, 在转移条件码出现之前不进行运算.
2. 另一种办法是让它运算完但不送回运算结果.
3. 采用后援寄存器法(实现效率会更高一些), 把可能被破坏的原始状态都用后援寄存器保存起来, 一旦猜错,就取出后援寄存器中的内容来恢复分支点的现场.
为了在猜错时能尽快回到原分支处转入另一分支, 在沿猜测路径向前流动的同时, 还可由存储器预取转移成功分支的头几条指令, 放在转移目标指令缓冲器中, 以便在猜错时不必从访存取p开始,减少流水线的等待时间.

加快和提前形成条件码的措施:
1. 加快单条指令内部条件码的形成, 不等指令执行完就提前形成反映运算结果的条件码.
2. 另一方面是在一段程序内提前形成条件码, 这特别适合于循环型程序的判断循环是否继续时的转移情况.

采取延迟转移: 这是用软件方法进行静态指令调度的技术, 不必增加硬件, 在编译生成目标指令程序时, 将转移指令与其前面不相关的一条或多条指令交换位置, 让成功转移总是延迟到在这一条或多条指令执行之后再进行.

加快短循环程序的处理: 
1. 可以将长度小于指缓容量的短循环程序整个一次性放入指缓内, 并暂停预取指令, 避免执行循环时由于指令预取导致指缓中需循环执行的指令被冲掉, 减少主存重复取指的次数.
2. 由于循环分支概率高, 因此, 让循环出口端的条件转移指令恒猜循环分支, 减少因条件分支造成流水线断流的机会.

中断会引起流水线断流, 但出现概率比条件转移的概率要低得多, 且又是随机发生的, 所以, 流水机器中断主要是如何处理好断点现场的保存和恢复, 而不是如何缩短流水线的断流时间.
早期使用“不精确断点”法(IBM360/91), 但由于不利于编程和程序的排错, 后来流水机器多采用“精确断点”法(Amdahl 470 V/6)


指令级高度并行的超级处理机: 超标量处理机、超长指令字处理机、超流水线处理机和超标量超流水线处理机.

在超标量流水线处理机中配置多套功能部件、指令译码电路和多组总线, 寄存器也备有多个端口和多组总线.超标量流水线处理机非常适合于求解像稀疏向量或稀疏矩阵这类标量计算问题. 因为它们用向量流水线处理机求解很不方便.
典型的超标量流水机有IBM RS/6000、 Power PC 601, DEC 21604、Power PC 620、Intel i960CA、Pentium、Tandem Cyclone、SUN Ultra SPAC和Motorola MC 88110
由于程序中指令并行性的开发有限, 因此, 超标量处理的度m比较低

超长指令字(VLIW)结构是将水平型微码和超标量处理两者相结合.指令字长可达数百位, 多个功能部件并发工作, 共享大容量寄存器堆.
超长指令字处理机的优点是所需拍数比超标量处理机的少, 指令译码容易, 开发标量操作间的随机并行性更方便, 从而可使指令级并行性较高.但是成功与否,取决于代码压缩的效率, 结构也不如超标量处理机的紧凑, 要同时设计系统结构和编译程序, 缺乏对传统硬件和软件的兼容, 不大适用于一般的应用领域, 所以结构的思想是好的, 却难以成为计算机的主流

典型的超长指令字处理机有Multiflow 公司的TARCE计算机和Cydrome公司的Cydra 5计算机, 每条指令字长为256位, 可并发执行7种操作.

超流水线处理机不同与超标量处理机和VLIW处理机, 每个单位时间仍只流出一条指令, 但是单位时间小 .
超标量处理机利用资源重复, 设置多个执行部件寄存器堆端口. 超流水线处理机则着重于开发时间并行性, 在公共的硬件上采用较短的时钟周期, 深度流水来提高速度, 需使用高速的时钟机制来实现.

超标量超流水线处理机是超标量流水线与超流水线处理机的结合.

向量处理机

向量处理机是有向量数据表示的处理机, 分向量流水处理机和阵列处理机两类. 向量流水处理机是以时间重叠途径开发的, 而阵列处理机是以资源重复途径开发的.


横向水平处理: 宜于在标量处理机上用循环程序实现, 但却难以使流水线连续流动.
纵向处理

分组纵横处理: 每一组内均按纵向方式处理, 而组和组之间则采用软件方法编制循环程序的方式依次循环处理. CRAY-1就是采用这种方式来进行向量的流水处理的. 

向量横向处理是向量的处理方式, 但不是向量的流水处理方式; 而向量纵向处理和分组纵横处理既是向量的处理方式, 也是向量的流水处理方式. 

向量流水处理机: cray-1 是由中央处理机、诊断维护控制处理机、大容量磁盘存储子系统、 前端处理机组成的功能分布异构型多处理机.

￼
提高向量流水处理的性能: 一般可采取让多个流水线功能部件并行, 流水线链接, 加快条件语句和稀疏矩阵处理, 加快向量的归约操作等办法.
前两者主要是加快相邻向量指令的执行, 后两者主要是让循环向量化.

Vi冲突和功能部件冲突:
Vi冲突: 指的是并行工作的各向量指令的源向量或结果向量使用了相同的Vi.
￼
功能部件冲突: 指的是同一个功能部件被要求并行工作的多条向量指令所使用.
￼
CRAY-1向量处理机的一个显著特点是只要不出现功能部件使用冲突和源向量寄存器使用冲突, 通过链接机构可使有数据相关的向量指令仍能大部分时间并行执行.
￼
流水链接建立时间
￼
此后每拍就可取得一个结果分量存入V4, 一共需要 17+(N-1).
如果第一、二条指令全执行完,最后再执行第三条指令, 1+6+(N-1)+1+7+1 + (N-1)
链接起来,省去了中间多次存的时间
链接的关键是: 只有前一条指令的第一个结果分量送入结果向量寄存器组的那一个时钟周期为允许链接的时间时才可以.可以链接的后续指令与前一条指令可以插入一些其他不相关的指令,只要不错过链接时间,就可以提高系统性能.
链接技术是提高计算机整体运算速度的一个非常重要的措施

阵列处理机有两种构形, 差别在于存储器的组成方式和互联网络的作用不同.
构形1, 采用分布式存储器阵列处理机的构形, 采用这种构形的阵列处理机是SIMD的主流, 典型的有ILLIAC IV、 MPP、DAP、CM-2、MP-1和DAP600系列等

构形2 采用集中式共享存储器的阵列处理机构形. 采用这种构形的典型机器有BSP

与向量处理的流水线处理机比, 阵列处理机利用的是资源重复, 而不是时间重叠; 利用的是并行性中的同时性, 而不是并发性.阵列处理机提高速度主要是靠增大处理机单元数, 比起向量流水处理机主要靠缩短时钟周期来说, 速度提高的潜力要大得多.
与流水线处理机不同的另一方面是阵列处理机使用简单、 规整的互联网络来确定处理单元间的连接.
阵列处理机在机间互连上比固定结构的单功能流水线灵活.

ILLIAC IV 采用分布式存储器构形: PU 为处理部件, 包含64位的算术处理单元PE, 64个处理部件PU. 处理单元是累加器型运算器
￼
ILLIAC IV 并行算法: 矩阵加(3条指令顺序执行, 64个元素并行相加)、矩阵乘、累加和.

SIMD计算机的互连网络

SIMD系统的互连网络的设计目标是: 结构不要过分复杂, 以降低成本; 互连要灵活, 以满足算法和应用的需要; 处理单元间信息交换所需的传送步数要尽可能少, 以提高速度性能; 能用规整单一的基本构件组合而成, 或者经过多次通过或者经多级连接来实现复杂的互连, 使模块性好, 以便于用VLSI实现并满足系统的可扩充性.

在确定PE之间通信的互连网络时, 需要对操作方式、控制策略、交换方法和网络的拓扑结构作出抉择

操作方式有同步、异步及同步与异步组合3种: 现有的阵列处理机根据其SIMD性质, 均采用同步操作方式, 让所有PE按时钟同步操作. 异步或组合操作方式一般多用于多处理机.

控制策略:  集中和分布, 多数现有的SIMD互连网络采用集中

交换方法主要有 线路交换、包交换及线路与包交换组合3种:  线路交换是在源和目的间建立实际的连接通路, 一般适合于大批量数据传输. 包交换是将数据置于包内传送, 不用建立实际的连接通路, 对短数据信息传送特别有效. SIMD互连网络多采用硬连的线路交换, 包交换则多用于处理机和计算机网络中.

网络的拓扑结构指的是互连网络入、出端可以连接的模式, 有静态和动态两种. 静态拓扑有一维的线型, 二维的环型、星型、树型、胖树型、网络型、脉动阵列型, 三维的弦环型、立方体型、环立方体型, 以及其他复杂的连接形式. 由于静态网络的灵活性、适应性差,很少使用.

动态网络有单级和多级两类 : 动态单级循环网络、 动态多级网络/多级循环网络.

基本的单级互连网络:  立方体、PM2I、混洗交换和蝶形单级网络.

立方体单级网络: 3中互连函数, Cube0、 Cube1、Cube2. , 单级立方体网络最大距离为n
￼

 
￼

PM2I单级网络: 是“加减2i”(Plus-Minus2i)单级网络的简称. 能实现与j号处理单元直接相连的是号位j加减2i的处理单元, 最大距离为N/2
￼
￼
处理器间用单向环网或双向环网互连, 是PM2I网络的特例, ILLIAC IV处理单元的互连也是PM2I的特例.

混洗交换单级网络: 包含两个互连函数, 一个是全混(Perfect Shuffle),另一个是交换(Exchange)
￼
Shuffle函数还有一个重要特性, 如果把它再做一次Shuffle函数变换, 得到一组新的代码, 经过n次全混后, 全部N个处理单元便又恢复到最初的排列次序.
￼
由于单纯的全混互连网络不能实现二进制编号为全“0”和全“1”的处理单元与其他处理单元的连接,因此还需要增加Cube0交换函数. 这就是全混交换单级网络. 在混洗交换网络中, 最远的两个入、出端口是全“0”和全“1”, 它们的连接需要n次交换和n-1次混洗, 所以最大距离为2n-1.
￼

蝶形单级网络的互连函数为:
Butterfly(Pn-1Pn-2…P1P0) = P0Pn-2…P1Pn-1. 即将二进制地址的最高位和最低位相互交换位置.
￼

基本的多级互连网络: 多级立方体网络、 多级混洗交换网络和多级PM2I网络.
￼
只有前两种功能的称二功能交换单元, 有全部四种功能的称四功能交换单元.

多级立方体网络的控制方式: 级控制、单元控制和部分级控制
级控制:  同一级的所有开关只用一个控制信号控制, 同时只能处于同一种状态.
单元控制: 每个开关都由自己独立的控制信号控制, 可各自处于不同的状态.
部分级控制: 第i级的所有开关分别用i+1个信号控制, 0 <= i <= n-1, n为级数.
利用上述交换开关、拓扑结构和控制方式3个参量, 可以描述各种多级互连网络的结构.

多级立方体网络: 有STARAN网络、间接二进制n方体网络等, 多级立方体网络的共同特点: 
第I级(0 <= I <= n - 1)交换单元处于交换状态时, 实现的是Cubei互连函数, 且都采用二功能交换单元.

两者差别在控制方式上, STARAN网络采用级控制(称交换网络)和部分级控制(其中可实现移数功能的称移数网络), 而间接二进制n方体网络用单元控制, 因此后者具有更大的连接灵活性.
￼

多级混洗交换网络: 又称omega网络,采用单元控制方式.
￼

多级PM2I网络

￼

比较上述各种多级网络, 灵活性由低到高的次序是: 级控制立方体、 部分级控制立方体、间接二进制n方体、omega、ADM, 而复杂性和成本的次序也相应增高.STARAN网络和omega网络都是为了进行存储器与处理单元之间的数据变换, 间接二进制n方体网络是为了连接成微处理器阵列, 但从上面对各种网络共同性的分析中可以看出, 它们对多种应用场合都是适合的.

基准网络
￼

多级交叉开关网络: 一种非阻塞式网络
￼
多级蝶式网络: 不能实现播送, 只是omega网络的一个有限制的子集

￼
全排列网络:能实现任意一个入端与任意一个出端间的连接, 但要同时实现两对或者多对入、出端间的连接时, 有可能发生争用数据传送路径的冲突, 有这类性质的互连网络称为阻塞式网络(Blocking Network), 没有这类性质的互连网络称为非阻塞式网络或全排列网络. 非阻塞式网络连接灵活, 但连接线多、控制复杂、成本高.

全排列网络的两种实现方法:
1. 对多级互联网络通行两次: 在多级互联网络的出端设置锁存器, 使数据在时间上顺序通行两次
2. 将多级互联网络和它的逆网络连在一起,可以省去中间完全重复的一级, 得到总级数为2log2N-1级的全排列网络

可重排列网络: 只要经过重新排列已有入、出端对的连接, 就可完成所有可能的入、出端间的连接而不发生冲突的互连网络.
循环多级互连网络的实现思路: 在多级互连网络的出端设置锁存器, 使数据在时间上顺序通行两次
￼


并行存储器的分体数m应取成质数, 才能较好地避免存储器访问的冲突. 只要变址跳距与m互质, 存储器访问就能无冲突地进行.
为了能使行或列的各元素都能并行访问, 采取将数据在存储器中错位存放,使并行存储器分体数m大于每次要访问的向量或数组元素的个数n, 且等于质数, 同时在多维数组的行、列等方向上采取不同的错开距离.

为了满足要求计算量很大的信号/图像处理及科学计算的特定算法的需要, 提出脉动阵列结构的脉动阵列处理机. 对特定问题具有极高的计算并行性.

脉动阵列结构是由一组处理单元(PE)构成的阵列. 每个PE的内部结构相同,一般由一个加法/逻辑运算部件或加法/乘法运算部件再加上若干锁存器构成,所有处理单元的数据锁存器都受同一个时钟控制.

脉动阵列结构的特点:
1. 结构简单、规整, 模块化强, 可扩充性好, 非常适合超大规模集成电路实现.
2. PE间数据通信距离短、规则, 使数据流和控制流的设计、同步控制等均简单规整
3. 脉动阵列中所有PE能同时运算, 具有极高的计算并行性, 可通过流水获得很高的运算效率和吞吐率.
4. 脉动阵列结构的构形与特定计算任务和算法密切相关, 具有某种专用性, 限制了应用范围,这对VLSI是不利的.

通用脉动阵列结构的3种发展途径:
1. 通过增设附加的硬件, 对阵列的拓扑结构和互连方式用可编程开关进行重构, 即经程序重新配置阵列的结构.(典型例子, CHiP)
2. 用软件把不同的算法映像到固定的阵列结构上
3. 探寻与问题大小无关的脉动处理方法, 以及VLSI运算系统的分割矩阵算法, 使它们可以克服阵列只能求解固定大小题目的缺陷, 同时探寻发展适合一类计算问题的通用算法和相应的设置方案.


多处理机是指由两台以上的处理机, 共享I/O子系统, 机间经共享主存或高速通信网络通信,在统一操作系统控制下, 协同求解大而复杂问题的计算机系统.

使用多处理机的目的: 一是通过多台处理机对多个作业、任务进行并行执行来提高解题速度, 从而提高系统的整体性能; 第二个目的是使用冗余的多处理机通过重新组织来提高系统的可靠性、适应性和可用性.

处理机可以有同构型、异构型和分布型3种

多处理机属于多指令流多数据流的系统: 与单指令流多数据流的主要差别来源于并行性的等级不同, 阵列处理机主要针对向量、数组处理, 实现向量指令操作级的并行, 是开发并行性中的同时性. 多处理机实现的则是更高一级的作业或任务间的并行, 是开发并行性中的并发性.

多处理机的并行性主要体现于指令的外部, 使程序并行性的识别比较困难.
多处理机要研究如何用专门的指令或语句来控制并行任务的派生;要研究如何将一个大的作业或任务进行分割, 合理选择任务的粒度大小和各任务粒度大小的均匀性.多处理机执行并发任务所需的处理机的机数是不固定的.必须研究如何较好地解决动态的资源分配和任务调度.让各处理机的负荷尽可能均衡, 并要防止死锁.
要研究多处理机中某个处理机发生故障后, 如何重新组织系统, 使之不至于瘫痪.


多处理机的硬件结构:  紧耦合和松耦合
紧耦合多处理机: 是通过共享主存实现处理机间通信的, 其通信速率受限于主存频宽. 为减少主存冲突, 主存采用模m多体交叉存取. 可自带高速缓冲存储器Cache, 以减少访主存次数.
紧耦合处理机有两种构形: 主要差别只在于是否自带专用的Cache;
￼
处理机间通过中断信号互连网络, 由一台处理机向另一台处理机发出中断信号, 实现处理机间的进程同步
处理机和连接外设的I/O通道经I/O-处理机互连网络来实现通信.

紧耦合处理机就各处理机而言, 又有同构对称型和异构非对称型.  当多处理机用于并行任务时, 常采用同构对称型的紧耦合多处理机.

松耦合处理机: 每台处理机都有一个容量较大的局部存储器, 用于存储经常用的指令和数据, 以减少紧耦合系统中存在的访主存冲突, 不同处理机间或者通过通道互连实现通信, 以共享某些外围设备; 或通过消息传送系统来交换信息.
松耦合多处理机可分为非层次型和层次型两种构形.

多处理机机间互连的形式是决定多处理机性能的一个重要因素. 一般采用总线、环形互连、交叉开关、多端口存储器、蠕虫穿洞寻径网络、开关枢纽结构形式(分布式结构)等几种形式.

为解决多处理机同时访问公用总线的冲突,研制静态优先级、固定时间片、动态优先级、先来先服务等多种总线仲裁算法.
多处理机的主存一般都采用多个模块构成的并行存储器.

多Cache的一致性问题的解决办法
1. 解决进程转移引起的多Cache不一致性: 通过禁止进程迁移的办法予以解决, 也可以在进程挂起时, 靠硬件方法将Cache中该进程改写过的信息强制写回主存相应位置的办法来解决
2. 以硬件为基础实现多Cache的一致性问题: 普遍采用监视Cache协议(Snoopy Protocol),即各个处理机中的Cache控制器随时都在监视着其他Cache的行动. 有写作废法和写更新法(播写法), 实现简单,但只适用于总线互连的处理机. 当处理机的机数很多,或者不采用总线互连时,监视Cache协议法就不适用了, 要采取其他的办法, 其中主要是目录表法, 分为: 全映像目录表法、有限目录表法、链式目录表法.
3. 以软件为基础实现多Cache的一致性: 靠软件限制, 不把一些公用的可写数据存入Cache中,将信息分为存入Cache的和不能存入Cache的两部分. 优点是可以降低硬件的复杂性, 降低对互连网络通信量的要求, 因而性能价格比可以较高, 比较适用于处理机数多的多处理机. 但由于可靠性及编译程序的编写困难, 都还没有真正在商品化处理机上使用.

并行算法: 是指可同时执行的多个进程的集合, 各进程可相互作用、协调和并发操作.
按运算基本对象,并行算法可分为数值型和非数值型.
按并行进程间的操作顺序不同, 并行算法又分为同步型、异步型和独立型3种
根据处理计算机任务的大小(即任务粒度)不同,并行算法又分为细粒度、中粒度和粗粒度3种
细粒度并行算法一般指向量或循环级的并行. 中粒度并行算法一般指较大的循环级并行, 并确保这种并行的好处可以补偿因并行带来的额外开销. 粗粒度并行算法则一般是指子任务级的并行.

用同构性来表示并行的各进程间的相似度. 一般多程序多数据流的多处理机上运行的进程之间是异构性的, 而在单程序多数据流的多处理机上运行的多个并行进程则是同构性的.

并行算法取决于计算机的结构和题目, 它是提高多处理机并行性能的关键.
研究并行算法的一种思路是将大的程序分解成可由足够多的并行处理的过程.


程序中各类数据相关是限制程序并行的重要因素.数据相关(先写后读)、 数据反相关(先读后写)、数据输出相关
￼
￼
￼
两个程序段之间若有先写后读的数据相关,不能并行, 只有在特殊情况下可以交换串行; 先读后写,可以并行执行,但必须保证其写入共享主存时的先读后写次序, 不能交换串行; 写-写相关,可以并行执行, 但同样需要保证其写入的先后次序, 不能交换串行; 同时有先写后读和先读后写两种相关, 以交换数据为目的时, 必须并行执行, 且读、写要完全同步,不许顺序串行和交换串行; 没有任何相关或仅有源数据相同时, 可以并行、顺序串行和交换串行.

并行程序设计语言的基本要求是: 能使程序员在其程序中灵活、方便地表示出各类并行性, 能在各种并行/向量计算机系统中高效地实现.
并行进程的特点是这些进程在时间上重叠地执行, 一个进程未结束,  另一个进程就已开始.

包含并行性的程序在多处理机上运行时, 需要有相应的控制机构来管理, 其中包括并行任务的派生和汇合.

因为多处理机总有不可并行的部分, 解题过程需要花费辅助开销,用于并行性检测, 并行任务的派生和汇合, 处理机间的通信传输、同步、系统控制和调度,使得多处理机的系统性能比期望的要低得多.
任务粒度(Task Granularity)的大小会显著影响多处理机的性能和效率, 任务粒度过小, 辅助开销大, 系统效率低; 任务粒度过大, 并行度低, 性能不会很高. 因此要合理选择任务粒度大小, 并使其尽可能均匀, 还要采取措施减少辅助开销, 以保证系统性能随处理机数目的增大能有较大的提高.

衡量任务粒度大小的一个依据是程序用于有效计算的执行时间E与处理机间的通信等辅助开销时间C的比值.

多处理机操作系统类型: 主从型、各自独立型及浮动型.
主从型: 管理程序只在一个指定的处理机(主处理机)上运行. 
优点: 结构比较简单; 整个管理程序只在一个处理机上运行, 除非某些需要递归调用或多重调用的公用程序, 一般都不必是可再入的; 另有一个处理机访问执行表, 不存在系统管理控制表格的访问冲突和阻塞, 简化了管理控制的实现.
缺点:  对主处理机的可靠性要求很高. 一旦发生故障, 很容易使整个系统瘫痪.
适用场合: 适用于工作负荷固定, 从处理机能力明显低于主处理机, 或由功能相差很大的处理机组成的异构型多处理机.

各自独立型: 将控制功能分散给多台处理机, 共同完成对整个系统的控制工作.
优点: 很适应分布处理的模块化结构特点, 减少对大型控制专用处理机的需求; 某个处理机发生故障, 不会引起整个系统瘫痪, 有较高的可靠性; 每台处理机都有其专用控制表格, 使访问系统表格的冲突较少, 也不会有许多公用的执行表, 同时控制进程和用户程序一起进行调度, 能取得较高的系统效率.
缺点: 实现复杂;
适用场合: 松耦合多处理机.

浮动型: 介于主从型和各自独立型操作系统之间的一种折中方式, 其管理程序可以在处理机间浮动.
优点: 各类资源可以较好地做到负荷平衡. 缺点: 设计最为困难
适用场合: 紧耦合多处理机, 特别是公共主存和I/O子系统的多个相同处理机组成的同构型多处理机.

多处理机的发展: 分布式共享存储器多处理机(采用Cache目录表来支持分布式Cache的一致性)、 对称多处理机、多向量多处理机、并行向量多处理机、大规模并行处理机和机群系统.

机群系统比起传统的并行处理系统有如下明显优点: 
1. 系统有高的性能价格比
2. 系统的开发周期短
3. 系统的可扩展性好
4. 系统的资源利用率高
5. 用户投资风险小
6. 用户编程方便


传统的Von Neumann型计算机采用控制驱动方式, 顺序地执行指令, 这很难最大限度地开发出计算的并行性, 为此提出若干非Neumann型计算机, 包括: 使用数据流语言, 基于数据驱动的数据流计算机; 使用函数式语言, 基于需求驱动的归约机

Von Neumann型计算机的基本特点是在程序计数器集中控制下, 顺次地执行指令, 因此, 它是以控制流方式工作的. 虽然可以在系统结构、程序语言、编译技术等方面进行改进, 发展流水线机、阵列机或多处理机, 但本质上仍是指令中在程序计数器控制下顺序执行, 这就很难最大限度地发掘出计算的并行性.

开发并行性的另一种途径是完全摆脱Von Neumann型的程序计数器控制驱动的控制流方式, 改用数据驱动的数据流方式来工作.
数据驱动的数据流方式指的是, 只要一条或一组指令所要求的操作数全部准备就绪, 就可以立即激发相应的指令或指令组执行. 执行结果的输出将送往等待这一数据的下一条或下一组指令. 如果其中一些指令因此而使所需用到的数据全部准备就绪, 就可以被激发执行. 因此, 在这种计算机上不需要程序计数器.

控制驱动的控制流方式的特点是: 通过访问共享存储单元让数据在指令之间传递; 指令执行的顺序性隐含于控制流中, 但却可以显式地使用专门的控制操作符来实现并行处理; 指令执行的顺序受程序计数器控制, 换句话说, 是受控制令牌所支配的. 数据驱动的数据流方式则不同, 它没有通常的共享变量概念, 即没有共享存储数据的概念; 指令执行顺序只受指令中数据相关性的制约; 数据是以数据令牌方式直接在指令之间传递的.

数据令牌是一种表示某一操作数或参数已准备就绪的标志.

数据驱动计算, 其操作是按输入数据可用性决定的次序进行的. 需求驱动计算, 其操作则按数据需求所决定的次序进行的. 前者只要所要求的输入数据全部就绪, 即可驱动操作执行, 是一种提前求值的策略;  而后者则按需求值, 只有当某一函数需要用到某一自变量时, 才驱动对该自变量的求值操作, 是一种滞后求值的策略. 显然后者较前者可以减少许多不必要的求值, 辅助开销少, 有助于提高系统的效率.

从语义上讲, 数据流是基于异步性和函数性的一种计算模型. 所谓异步性, 是指一旦操作数到齐就开始执行, 这是数据流计算机开拓并行性的基础. 所谓函数性, 是指每一数据流操作都是消耗一组输入值, 产生一组输出值而不发生副作用, 具有变量出现在赋值语句左边仅一次的单赋值特性, 从而保证任何两个并发操作可以按任意次序执行, 而不会互相干扰.

数据流程序图中程序的执行过程是一种数据不断进行激发(驱动)的过程.一个操作符的执行从每个输入端只吸收一个令牌,进行计算后, 只在有效的输出端上产生一个输出令牌. 这种单赋值规则使结点在生成和消灭时, 可以有序地分配和回收值, 而不会产生竞争.

为满足数据流计算机程序设计的需要,引入的结点:
1. 常数产生结点(Identify)
2. 算逻运算操作结点(Operator)
3. 复制操作结点(Copy)
4. 判定操作结点(Decider)
5. 控制类操作结点
此外,根据数据流程序设计的需要, 还可以设计一些其他的基本结点和功能更强的复合型结点
数据流程序图的另一种表示方法更接近于机器语言, 也更容易理解机器的工作原理: 活动模片表示法.

数据流程序图实际上是数据流计算机的机器语言, 优点是直观易懂, 但编程效率很低, 难以为一般用户所接受. 为此, 需要研究适合于数据流计算机使用的高级语言.
目前主要有单赋值语言和函数程序设计语言. 另外, 像逻辑程序设计语言PROLOG这样一类的描述式语言, 也可用作数据流计算机的高级语言.

单赋值语言是指在程序中, 每个量均只赋值一次, 即同一个量名在不同赋值语句的左部最多只出现一次.
著名的单赋值语言有美国的ID(Irivne Data Flow)语言、VAL(Value Oriented Algorihm Language)语言、法国的LAU语言、 英国曼彻斯特大学的SISAL语言等

单赋值语言具备的基本特点:
1. 遵循单赋值规则
2. 有丰富的数据类型
3. 具有很强的类型性
4. 具有模块化结构的程序设计思想;
5. 没有全局存储器和状态的概念.
6. 程序不规定语句的执行顺序.

根据对数据令牌处理的方式不同, 可以把数据流计算机的结构分成静态和动态两类.
静态数据流计算机:  数据令牌没有加标号. 为了满足迭代要求, 除要多次重复激活同一操作结点外, 还必须另设控制令牌, 以识别数据令牌由一个结点传送到另一个结点的时间关系, 从而区分属于不同迭代层次的各批数据. 所以静态数据流计算机不支持递归的并发激活, 只支持一般的循环.

动态数据流计算机:  主要特点是让令牌带上标记, 使得在任意给定时刻, 数据流程序图任何一条弧上允许出现多个带不同标记的令牌.令牌的标记是令牌附带的一个能识别该令牌时间先后相对关系的标号. 有的计算机上也称其为颜色. 多组数据令牌的指令, 通过对令牌标记的配对来识别,需要相应硬件将标记附加到数据令牌上, 完成对标记的匹配工作.

数据流计算机在提高并行处理效能上有着显著的优点,但也存在问题:
1. 数据流计算机的主要目的是为了提高操作级并行的开发水平, 但如果题目本身数据相关性很强, 内涵并行性成分不多时, 就会使效率反而比传统的Von Neumann型机的还要低
2. 在数据流计算机中为给数据建立、识别、处理标记, 需要花费较多的辅助开销和较大的存储空间, 但如果不用标记, 则无法递归并会降低并行能力.
3. 数据流计算机不保存数组, 对标量运算有力, 而对数组、递归及其他高级操作较难管理.
4. 数据流语言的变量代表数值, 而不是存储单元位置, 使程序员无法控制存储分配, 为有效回收不用的存储单元, 增大了编译程序的难度.
5. 数据流计算机互联网络设计困难, 输入/输出系统仍不够完善.
6. 数据流计算机没有程序计数器, 给诊断和维护带来了困难.
因此数据流计算机尚难批量生产, 仍需进一步改进. 从发展来看, 有很大潜力. 在并行度低的小型机及需要高度并行的超级机上有潜在的发展余地, 但在中型的并行机上可能较难使用.

新的数据流计算机: 
1. 采用提高并行度等级的数据流计算机
2. 采用同、异步结合的数据流计算机
3. 采用控制流与数据流相结合的数据流计算机

归约机: 和数据流计算机一样, 都是基于数据流的计算模型.只是其采用的驱动方式不同.数据流计算机采用数据驱动, 执行的操作序列取决于输入数据的可用性; 归约机则是需求驱动, 执行的操作序列取决于对数据的需求, 对数据的需求又来源于函数式程序设计语言对表达式的归纳.

函数式语言是由所有函数表达式的集合、所有目标的集合及所有由函数表达式到目标的函数集合三部分组成. 函数是其基本成分, 是从一批目标到另一批目标的映射.
归约机: 必须针对函数程序设计语言的特点和问题来设计支持函数式程序运行的新计算机.
归约机的特点:
1. 应当面向函数式语言, 或以函数式语言为机器语言的非Neumann型机器, 其内部结构应不同于Neumann型机器
2. 具有大容量物理存储器并采用大虚存容量的虚拟存储器, 具备高效的动态存储分配和管理的软、硬件支持, 满足归约机对动态存储分配及所需存储空间大的要求.
3. 处理部分应当是一种由多个处理器或多个处理机并行的结构形式, 以发挥函数式程序并行处理的特长.
4. 采用适合于函数式程序运行的多处理器互连的结构, 最好采用树形方式的互连结构或多层次复合的互连结构形式.
5. 为减少进程调度及进程间的通信开销, 尽量把运行进程的结点机紧靠该进程所需用的数据安排 , 并使运行时需相互通信的进程所占用的处理机也靠近, 让各处理机的负荷平衡.
根据计算机内部对函数表达式所用存储方式的不同,将归约方式分成串归约和图归约两类
归约方式体现了按需求驱动的思想, 根据对函数求值的需求来激活相应的指令.
根据计算机所用归约方式不同,相应的就有串归约机和图归约机两类


